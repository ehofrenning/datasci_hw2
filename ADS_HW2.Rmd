---
title: "ADS_HW2"
author: "Ekaterina Hofrenning"
date: "3/28/2021"
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```


```{r libraries}
# SEE modeldata package for new datasets
library(tidyverse)         # for graphing and data cleaning
library(tidymodels)        # for modeling
library(stacks)            # for stacking models
library(naniar)            # for examining missing values (NAs)
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(DALEX)             # for model interpretation  
library(DALEXtra)          # for extension of DALEX
library(patchwork)         # for combining plots nicely
theme_set(theme_minimal()) # Lisa's favorite theme
```

```{r data}
data("lending_club")
# Data dictionary (as close as I could find): https://www.kaggle.com/wordsforthewise/lending-club/discussion/170691
```


**HW 2 GitHub link** : https://github.com/ehofrenning/datasci_hw2


\


## Modeling

*1. Explore the data, concentrating on examining distributions of variables and examining missing values.*

```{r}
data(lending_club)
head(lending_club)
```


I first explore some main predictors via visualizations to examine the distributions:

```{r}
ggplot(lending_club, aes(x = funded_amnt)) +
  geom_density() +
  labs(title = "Funded Amount distribution") +
  xlab("Funded amount")

ggplot(lending_club, aes(x = int_rate)) +
  geom_histogram(bins = 40) +
  labs(title = "Interest rate distribution") +
  xlab("Interest rate")

ggplot(lending_club, aes(x = annual_inc)) +
  geom_histogram(bins = 150) +
  labs(title = "Annual income distribution") +
  xlab("Annual income")

# There are many more "good" loans than "bad"...:
ggplot(lending_club, aes(x = Class)) +
  geom_bar()
```


Here, I explore certain variables that I think may be all missing:

```{r}
lending_club %>%
  filter(acc_now_delinq == 1)

# THIS variable is all 0
lending_club %>%
  filter(delinq_amnt == 1)
```

From the above data exploration, I learned that I need to take out the *delinq_amnt* variable because all observations have a 0 (0 variance vector). I am chosing to leave in the other predictors at the moment, because I believe that we could theoretically have all this information in the real world when running a model like this.

*Do any data cleaning steps that need to happen before the model is build. For example, you might remove any variables that mean the same thing as the response variable (not sure if that happens here), get rid of rows where all variables have missing values, etc.*

First, I omit the 0 variance predictors:
```{r}
# Getting rid of delinq_amnt
lending <-
lending_club %>%
  select(-delinq_amnt)
```

Then, I upsample the "bad" classes because they are hugely underrepresented in the data. See comments for further clarification.: 
```{r}
#Be sure to add more “bad” Classes. This is not the best solution, but it will work for now. (Should investigate how to appropriately use step_sample_up() function from themis).

# in an ideal world, we would want to upsample training data and apply it to untouched testing data... but this is fine.

create_more_bad <- lending %>% 
  filter(Class == "bad") %>% 
  sample_n(size = 3000, replace = TRUE)

lending_club_mod <- lending %>% 
  bind_rows(create_more_bad)
```


*3. Split the data into training and test, putting 75% in the training data.*

```{r}
set.seed(494) # for reproducibility

# split the data
lending_split <- initial_split(lending_club_mod, prop = .75, strata = Class)

# make training/test sets
lending_training <- training(lending_split)
lending_testing <- testing(lending_split)
```


*4. Set up the recipe and the pre-processing steps to build a lasso model. Some steps you should take:*

Make all integer variables numeric (I’d highly recommend using step_mutate_at() or this will be a lot of code). We’ll want to do this for the model interpretation we’ll do later.
Think about grouping factor variables with many levels.
Make categorical variables dummy variables (make sure NOT to do this to the outcome variable).
Normalize quantitative variables.

```{r}
# Make integers into numeric
lending_training[12:21] <- lapply(lending_training[12:21], as.numeric)
lending_training[9:10] <- lapply(lending_training[9:10], as.numeric)
lending_training[1] <- lapply(lending_training[1], as.numeric)

# Other pre-processing steps:
lending_recipe <- recipe(Class ~ ., data = lending_training) %>%
  step_normalize(all_numeric()) %>%   # normalize quant vars
  step_dummy(all_nominal(), -all_outcomes())   # make categorical vars into dummy EXCEPT for outcome

# check to see that this all worked
prep(lending_recipe) %>%
  juice() %>%
  head()
```


*5. Set up the lasso model and workflow. We will tune the penalty parameter.*

```{r}
# define lasso model
lending_lasso <- 
  logistic_reg(mixture = 1) %>%   # 1 indicates lasso
  set_engine("glmnet") %>%
  set_args(penalty = tune()) %>%   #we'll tune the lambda later
  set_mode("classification")
```

```{r}
# define LASSO workflow
lasso_wf <-
  workflow() %>%
  add_recipe(lending_recipe) %>%   #the processed data
  add_model(lending_lasso)     #the general lasso model
lasso_wf
```


*6. Set up the model tuning for the penalty parameter. Be sure to add the control_stack_grid() for the control argument so we can use these results later when we stack. Find the accuracy and area under the roc curve for the model with the best tuning parameter. Use 5-fold cv.*

Creating some sets and vectors for the tuning process:
```{r}
# 5-fold cv 
lending_cv <- vfold_cv(lending_training, v = 5)

# create penalty grid 
penalty_grid <- grid_regular(penalty(), levels = 10)

# create control grid (this we need for stacking i think)
ctrl_grid <- control_stack_grid()
```


Tuning process (MAXIMIZE ACCURACY):
```{r}
# tune
lending_lasso_tune <- 
  lasso_wf %>%
  tune_grid(resamples = lending_cv,
            grid = penalty_grid,
            control = ctrl_grid)

#choose best penalty
best_param <- lending_lasso_tune %>% 
  select_best(metric = "accuracy")
best_param

# finalize workflow
lending_lasso_final_wf <- lasso_wf %>% 
  finalize_workflow(best_param)

# fit final model with the best lambda on training data
lending_lasso_final_mod <- lending_lasso_final_wf %>% 
  fit(data = lending_training)


# Fit model with best tuning parameter(s) to training data and apply to test data
lending_lasso_test <- lending_lasso_final_wf %>% 
  last_fit(lending_split)

# Metrics for model applied to test data
lending_lasso_test %>% 
  collect_metrics()
```

best lambda = 0.005994843


I THINK I CAN DELETE THIS BELOW:
```{r}
# Training data model accuracy:

# Accuracy
lending_lasso_tune %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  summarise(mean_accuracy = mean(mean))

# ROC AUC
lending_lasso_tune %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  summarise(roc_auc = mean(mean))
```

I THINK I CAN DELETE THIS BELOW:
```{r}
# SAME THING BUT FOR ROC AUC

#best param
#best_param2 <- lending_lasso_tune %>% 
#  select_best(metric = "roc_auc")

# finalize workflow
#lending_lasso_final_wf2 <- lasso_wf %>% 
#  finalize_workflow(best_param2)

# fit final model with the best lambda
#lending_lasso_final_mod2 <- lending_lasso_final_wf %>% 
#  fit(data = lending_training)

# average roc_auc
#lending_lasso_tune %>%
#  collect_metrics() %>%
#  filter(.metric == "roc_auc") %>%
#  summarise(roc_auc = mean(mean))
```



*7. Set up the recipe and the pre-processing steps to build a random forest model. You shouldn’t have to do as many steps. The only step you should need to do is making all integers numeric*

```{r}
# random forest recipe
ranger_recipe <- 
  recipe(formula = Class ~ ., 
         data = lending_training)

ranger_recipe %>%
  prep() %>%
  juice()
```


*8. Set up the random forest model and workflow. We will tune the mtry and min_n parameters and set the number of trees, trees, to 100 (otherwise the next steps take too long).*

```{r}
# set up, leave mtry and min_n to be tuned
ranger_spec <- 
  rand_forest(mtry = tune(),
              trees = 100,
              min_n = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("ranger")

# create initial workflow
ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec) 
ranger_workflow

 # fit the model
library(ranger)

#ranger_fit <- ranger_workflow %>% 
#  fit(lending_training)
#ranger_fit
```


*9. Set up the model tuning for both the mtry and min_n parameters. Be sure to add the control_stack_grid() for the control argument so we can use these results later when we stack. Use only 3 levels in the grid. For the mtry parameter, you need to put finalize(mtry(), lending_training %>% select(-Class)) in as an argument instead of just mtry(), where lending_training is the name of your training data. This is because the mtry() grid will otherwise have unknowns in it. This part can take a while to run.*

Tuning process:
```{r}
# make 5 fold cv sets
lending_cv <- vfold_cv(lending_training, v = 5)
# this is for stacking
ctrl_grid <- control_stack_grid()
```


```{r}
doParallel::registerDoParallel()

lending_forest_tune <- 
  ranger_workflow %>%
  tune_grid(resamples = lending_cv,
            grid = 20,
            control = ctrl_grid)
```


*10. Find the best tuning parameters. What is the are the accuracy and area under the ROC curve for the model with those tuning parameters?*

```{r}
# Accuracy
best_acc <-
lending_forest_tune %>%
  select_best("accuracy")
best_acc

# final model using highest accuracy tuning parameters
final_rf1 <- finalize_model(
  ranger_spec,
  best_acc)
final_rf1
```

```{r}
# put the best tuned model into final workflow
ranger_final_wf <- ranger_workflow %>% 
  finalize_workflow(best_acc)
ranger_final_wf

# fit ranger model to training data
ranger_fit <- ranger_final_wf %>% 
  fit(lending_training)

# Fit model with best tuning parameter(s) to training data and apply to test data
ranger_test <- ranger_final_wf %>% 
  last_fit(lending_split)

# get accuracy and ROC AUC for tuned model:
ranger_test %>%
  collect_metrics()
```

Accuracy: 0.9978220
ROC AUC: 0.9981551	



*11. Use functions from the DALEX and DALEXtra libraries to create a histogram and boxplot of the residuals from the training data. How do they look? Any interesting behavior?*

```{r}
lending_training$Class <- as.numeric(lending_training$Class)
lending_training

# create lasso explainer
lasso_explain <- 
  explain_tidymodels(
    model = lending_lasso_final_mod,
    data = lending_training %>% select(-Class), 
    y = lending_training %>% pull(Class),
    label = "lasso",
    type = "classification")

lasso_explain
```

```{r}
# RF explainer
rf_explain <- 
  explain_tidymodels(
    model = ranger_fit,
    data = lending_training %>% select(-Class), 
    y = lending_training %>% pull(Class),
    label = "rf",
    type = "classification")

rf_explain
```

```{r}
lasso_mod_perf <- model_performance(lasso_explain)
rf_mod_perf <-  model_performance(rf_explain)

hist_plot <- 
  plot(lasso_mod_perf,
       rf_mod_perf, 
       geom = "histogram")
box_plot <-
  plot(rf_mod_perf, lasso_mod_perf,
       geom = "boxplot")

hist_plot
box_plot
```
In this case, the values of the outcome variable, Class, are coded as twos and ones so it makes sense that the residuals would be vaguely surrounding 1. It seems that the random forest residuals are much more spread and not consistently around 1, compared to the lasso. 


*12. Use DALEX functions to create a variable importance plot from this model. What are the most important variables?*

```{r}
set.seed(10) #since we are sampling & permuting, we set a seed so we can replicate the results
lasso_var_imp <- 
  model_parts(lasso_explain)

plot(lasso_var_imp, show_boxplots = TRUE)
```

The loan's interest rate, open_il_12m, addr_state, term of the loan, and inq_fi are some important predictors. 


*13. Write a function called cp_profile to make a CP profile. The function will take an explainer, a new observation, and a variable name as its arguments and create a CP profile for a quantitative predictor variable. You will need to use the predict_profile() function inside the function you create - put the variable name there so the plotting part is easier. You’ll also want to use aes_string() rather than aes() and quote the variables. Use the cp_profile() function to create one CP profile of your choosing. Be sure to choose a variable that is numeric, not integer. There seem to be issues with those that I’m looking into.*




*14. Use DALEX functions to create partial dependence plots (with the CP profiles in gray) for the 3-4 most important variables. If the important variables are categorical, you can instead make a CP profile for 3 observations in the dataset and discuss how you could go about constructing a partial dependence plot for a categorical variable (you don’t have to code it, but you can if you want an extra challenge). If it ever gives you an error that says, “Error: Can’t convert from VARIABLE to VARIABLE due to loss of precision”, then remove that variable from the list. I seem to have figured out why it’s doing that, but I don’t know how to fix it yet.*


*15. Fit one more model type of your choosing that will feed into the stacking model.*


*16. Create a model stack with the candidate models from the previous parts of the exercise and use the blend_predictions() function to find the coefficients of the stacked model. Create a plot examining the performance metrics for the different penalty parameters to assure you have captured the best one. If not, adjust the penalty. (HINT: use the autoplot() function). Which models are contributing most?*


*17. Fit the final stacked model using fit_members(). Apply the model to the test data and report the accuracy and area under the curve. Create a graph of the ROC and construct a confusion matrix. Comment on what you see. Save this final model using the saveRDS() function - see the Use the model section of the tidymodels intro. We are going to use the model in the next part. You’ll want to save it in the folder where you create your shiny app.*



\
\



## Shiny App

If you are new to Shiny apps or it’s been awhile since you’ve made one, visit the Shiny links on our course Resource page. I would recommend starting with my resource because it will be the most basic. You won’t be doing anything super fancy in this app.

Everyone should watch the Theming Shiny talk by Carson Sievert so you can make your app look amazing.

Tasks:

You are going to create an app that allows a user to explore how the predicted probability of a loan being paid back (or maybe just the predicted class - either “good” or “bad”) changes depending on the values of the predictor variables.

*Specifically, you will do the following:*

Set up a separate project and GitHub repo for this app. Make sure the saved model from the previous problem is also in that folder. The app needs to be created in a file called exactly app.R that is also in the project folder.

At the top of the file, load any libraries you use in the app.

Use the readRDS() function to load the model.

You may want to load some of the data to use

Create a user interface (using the various *Input() functions) where someone could enter values for each variable that feeds into the model. You will want to think hard about which types of *Input() functions to use. Think about how you can best prevent mistakes (eg. entering free text could lead to many mistakes).

Another part of the user interface will allow them to choose a variable (you can limit this to only the quantitative variables) where they can explore the effects of changing that variable, holding all others constant.

After the user has entered all the required values, the output will be a CP profile with the the predicted value for the data that was entered, indicated by a point. I don’t think the functions from DALEX and DALEXtra will work with a stacked model, so you’ll likely have to (get to) do some of your own coding.

Use the bslib to theme your shiny app!

Publish your app to shinyapps.io. There are instructions for doing that on the tutorial I linked to above.

Write a paragraph or two describing your app on your website! Link to the app and your GitHub repository in your post. Include a link to your post here.




\
\

## Coded Bias

insert paragraph here.

